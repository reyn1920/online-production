# Enhanced Docker Compose with Scaling and Load Balancing Support
version: "3.8"

services:
  # Load Balancer (HAProxy)
  load-balancer:
    image: haproxy:2.8-alpine
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # HAProxy stats
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./ssl:/etc/ssl/certs:ro
    depends_on:
      - api
      - backend
      - content-agent
      - marketing-agent
    networks:
      - trae-network
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Database Services (Single instances for consistency)
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: trae_ai_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf
    networks:
      - trae-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    networks:
      - trae-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped

  # Message Queue with clustering support
  rabbitmq:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 0.8
      RABBITMQ_DISK_FREE_LIMIT: 2GB
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    networks:
      - trae-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped

  # Scalable API Service
  api:
    build: .
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/trae_ai_db
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://admin:admin123@rabbitmq:5672/- ENVIRONMENT=production
      - WORKER_PROCESSES=4
      - MAX_REQUESTS=1000
      - MAX_REQUESTS_JITTER=100
      - PROMETHEUS_METRICS_PORT=9090
    volumes:
      - .:/code
      - api_logs:/var/log/api
    working_dir:/code
    networks:
      - trae-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 20s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    restart: unless-stopped

  # Scalable Backend Service
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/trae_ai_db
      - REDIS_URL=redis://redis:6379
      - RABBITMQ_URL=amqp://admin:admin123@rabbitmq:5672/- ENVIRONMENT=production
      - CONTENT_AGENT_URL=http://content-agent:8001
      - MARKETING_AGENT_URL=http://marketing-agent:8002
      - MONETIZATION_AGENT_URL=http://monetization-bundle:8003
      - ANALYTICS_AGENT_URL=http://analytics-dashboard:8004
      - PROMETHEUS_METRICS_PORT=9091
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - trae-network
    volumes:
      - ./storage:/app/storage
      - backend_logs:/var/log/backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.75'
          memory: 768M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    restart: unless-stopped

  # Scalable Content Agent Service
  content-agent:
    build:
      context: ./content-agent
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/trae_ai_db
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER=redis://redis:6379/1
      - CELERY_BACKEND=redis://redis:6379/1
      - RABBITMQ_URL=amqp://admin:admin123@rabbitmq:5672/- ENVIRONMENT=production
      - USE_MOCK=false
      - PROMETHEUS_METRICS_PORT=9092
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - STABILITY_API_KEY=${STABILITY_API_KEY}
      - REPLICATE_API_TOKEN=${REPLICATE_API_TOKEN}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - trae-network
    volumes:
      - content_storage:/app/storage
      - ./content-agent/templates:/app/templates
      - content_logs:/var/log/content-agent
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    restart: unless-stopped

  # Scalable Marketing Agent Service
  marketing-agent:
    build:
      context: ./marketing-agent
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/trae_ai_db
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER=redis://redis:6379/1
      - CELERY_BACKEND=redis://redis:6379/1
      - RABBITMQ_URL=amqp://admin:admin123@rabbitmq:5672/- ENVIRONMENT=production
      - USE_MOCK=false
      - CONTENT_AGENT_URL=http://content-agent:8001
      - PROMETHEUS_METRICS_PORT=9093
      - FACEBOOK_APP_ID=${FACEBOOK_APP_ID}
      - TWITTER_API_KEY=${TWITTER_API_KEY}
      - LINKEDIN_ACCESS_TOKEN=${LINKEDIN_ACCESS_TOKEN}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      content-agent:
        condition: service_healthy
    networks:
      - trae-network
    volumes:
      - marketing_storage:/app/storage
      - marketing_logs:/var/log/marketing-agent
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.75'
          memory: 768M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    restart: unless-stopped

  # Monitoring Services
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - trae-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana_dashboards.json:/var/lib/grafana/dashboards/main.json
    networks:
      - trae-network
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Metrics Exporters
  node-exporter:
    image: prom/node-exporter:latest
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    volumes:
      -/proc:/host/proc:ro
      -/sys:/host/sys:ro
      -/:/rootfs:ro
    networks:
      - trae-network
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8081:8080"
    volumes:
      -/:/rootfs:ro
      -/var/run:/var/run:rw
      -/sys:/sys:ro
      -/var/lib/docker/:/var/lib/docker:ro
    networks:
      - trae-network
    restart: unless-stopped

  # Auto-scaling Controller (Custom)
  autoscaler:
    build:
      context: ./monitoring
      dockerfile: Dockerfile.autoscaler
    environment:
      - PROMETHEUS_URL=http://prometheus:9090
      - DOCKER_HOST=unix:///var/run/docker.sock
      - SCALING_RULES_CONFIG=/app/config/scaling-rules.yaml
      - CHECK_INTERVAL=30
      - SCALE_UP_THRESHOLD=70
      - SCALE_DOWN_THRESHOLD=30
      - MIN_REPLICAS=1
      - MAX_REPLICAS=10
    volumes:
      -/var/run/docker.sock:/var/run/docker.sock
      - ./monitoring/scaling-rules.yaml:/app/config/scaling-rules.yaml
    networks:
      - trae-network
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  content_storage:
    driver: local
  marketing_storage:
    driver: local
  monetization_storage:
    driver: local
  analytics_storage:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  api_logs:
    driver: local
  backend_logs:
    driver: local
  content_logs:
    driver: local
  marketing_logs:
    driver: local

networks:
  trae-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1

# Scaling commands:
# docker-compose -f docker-compose.scaling.yml up --scale api=5 --scale backend=3 --scale content-agent=4
# docker-compose -f docker-compose.scaling.yml up --scale marketing-agent=3 --scale monetization-bundle=2